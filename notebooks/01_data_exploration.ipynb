{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Data Exploration\n",
    "\n",
    "This notebook explores the LMSYS dataset structure and computes initial descriptive statistics.\n",
    "\n",
    "## Goals\n",
    "1. Load and understand the dataset structure\n",
    "2. Examine conversation patterns\n",
    "3. Understand user behavior and return patterns\n",
    "4. Identify potential confounders for causal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_syco.data.download import download_lmsys\n",
    "\n",
    "df_raw = download_lmsys()\n",
    "print(f\"Dataset shape: {df_raw.shape}\")\n",
    "print(f\"\\nColumns: {list(df_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Battle Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_syco.data.process import build_battle_table\n",
    "\n",
    "battles = build_battle_table(df_raw)\n",
    "print(f\"Battle table shape: {battles.shape}\")\n",
    "battles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Winner Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_counts = battles['winner'].value_counts()\n",
    "print(winner_counts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "winner_counts.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Winner Distribution')\n",
    "ax.set_ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common models\n",
    "model_counts = battles['model_a'].value_counts().head(15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "model_counts.plot(kind='barh', ax=ax)\n",
    "ax.set_title('Top 15 Models (Side A)')\n",
    "ax.set_xlabel('Count')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Response Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_syco.features.lexical import compute_response_length_features\n",
    "\n",
    "battles_with_length = compute_response_length_features(battles)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(battles_with_length['assistant_a_word_count'].clip(0, 500), bins=50, alpha=0.7)\n",
    "axes[0].set_title('Response A: Word Count')\n",
    "axes[0].set_xlabel('Words')\n",
    "\n",
    "axes[1].hist(battles_with_length['assistant_b_word_count'].clip(0, 500), bins=50, alpha=0.7)\n",
    "axes[1].set_title('Response B: Word Count')\n",
    "axes[1].set_xlabel('Words')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_syco.features.topics import compute_topic_features, get_topic_distribution\n",
    "\n",
    "battles_with_topics = compute_topic_features(battles)\n",
    "topic_dist = get_topic_distribution(battles_with_topics)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "topic_dist.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Topic Distribution')\n",
    "ax.set_ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lexical Sycophancy Signals (Heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_syco.features.lexical import compute_lexical_features\n",
    "\n",
    "battles_lex = compute_lexical_features(battles, 'assistant_a')\n",
    "\n",
    "print(\"Lexical sycophancy signals in assistant_a responses:\")\n",
    "for col in ['lex_flattery_count', 'lex_validation_seeking_count', 'lex_agreement_count']:\n",
    "    if col in battles_lex.columns:\n",
    "        print(f\"  {col}: mean={battles_lex[col].mean():.2f}, max={battles_lex[col].max()}\")\n",
    "\n",
    "print(f\"\\nResponses with any lexical sycophancy signal: {battles_lex['lex_sycophancy_any'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sample Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few examples\n",
    "sample = battles.sample(3, random_state=42)\n",
    "\n",
    "for i, (_, row) in enumerate(sample.iterrows()):\n",
    "    print(f\"=== Example {i+1} ===\")\n",
    "    print(f\"Winner: {row['winner']}\")\n",
    "    print(f\"Model A: {row['model_a']} | Model B: {row['model_b']}\")\n",
    "    print(f\"\\nUser: {row['user_prompt'][:300]}...\")\n",
    "    print(f\"\\nAssistant A: {str(row['assistant_a'])[:300]}...\")\n",
    "    print(f\"\\nAssistant B: {str(row['assistant_b'])[:300]}...\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Run sycophancy labeling: `make label`\n",
    "2. Continue with `02_labeling_validation.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
