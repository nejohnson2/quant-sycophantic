{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04: Causal Modeling\n",
    "\n",
    "This notebook estimates causal effects of sycophancy on user engagement.\n",
    "\n",
    "## Research Questions\n",
    "1. Does sycophancy causally affect battle outcomes?\n",
    "2. Does sycophancy affect user return rates?\n",
    "3. Are these effects heterogeneous across topics?\n",
    "\n",
    "## Methodology\n",
    "- Control for confounders: model quality, topic, response length, politeness\n",
    "- Propensity score weighting\n",
    "- Regression with controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_syco.data.process import build_battle_table, compute_all_metrics\n",
    "from quant_syco.features.topics import compute_topic_features\n",
    "from quant_syco.features.lexical import compute_response_length_features\n",
    "from quant_syco.config import LABELS_DIR\n",
    "\n",
    "# Load battles with all features\n",
    "battles = build_battle_table()\n",
    "battles = compute_topic_features(battles)\n",
    "battles = compute_response_length_features(battles)\n",
    "\n",
    "# Load labels\n",
    "label_files = list(LABELS_DIR.glob('labels_*_merged.parquet'))\n",
    "labels = pd.read_parquet(label_files[0])\n",
    "\n",
    "# Merge\n",
    "df = battles.merge(labels, on='question_id', how='inner')\n",
    "\n",
    "# Add return metrics if available\n",
    "try:\n",
    "    metrics = compute_all_metrics()\n",
    "    returns = metrics['returns'][['question_id', 'returned_7d', 'returned_30d']]\n",
    "    df = df.merge(returns, on='question_id', how='left')\n",
    "except Exception as e:\n",
    "    print(f\"Could not load return metrics: {e}\")\n",
    "\n",
    "print(f\"Analysis dataset: {len(df):,} battles\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Covariates and Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary outcome: A wins\n",
    "df_model = df[df['winner'].isin(['model_a', 'model_b'])].copy()\n",
    "df_model['a_wins'] = (df_model['winner'] == 'model_a').astype(int)\n",
    "\n",
    "# Create sycophancy differential\n",
    "df_model['syco_diff'] = df_model['sycophancy_a'] - df_model['sycophancy_b']\n",
    "df_model['polite_diff'] = df_model['politeness_a'] - df_model['politeness_b']\n",
    "df_model['length_diff'] = df_model['assistant_a_word_count'] - df_model['assistant_b_word_count']\n",
    "\n",
    "# Drop missing\n",
    "analysis_cols = ['a_wins', 'syco_diff', 'polite_diff', 'length_diff', 'topic']\n",
    "df_model = df_model.dropna(subset=analysis_cols)\n",
    "\n",
    "print(f\"Analysis sample: {len(df_model):,} battles (excluding ties and missing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Winner Model: Sycophancy Effect on Battle Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_syco.analysis.causal import run_winner_regression\n",
    "\n",
    "# Simple model\n",
    "result = run_winner_regression(\n",
    "    df_model,\n",
    "    sycophancy_a_col='sycophancy_a',\n",
    "    sycophancy_b_col='sycophancy_b',\n",
    "    politeness_a_col='politeness_a',\n",
    "    politeness_b_col='politeness_b',\n",
    "    control_cols=['topic', 'length_diff'],\n",
    ")\n",
    "\n",
    "print(\"WINNER REGRESSION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nSycophancy Differential Effect:\")\n",
    "print(f\"  Coefficient: {result['syco_diff_coef']:.3f}\")\n",
    "print(f\"  Odds Ratio: {result['syco_diff_or']:.3f}\")\n",
    "print(f\"  P-value: {result['syco_diff_pval']:.4f}\")\n",
    "print(f\"\\nPoliteness Differential Effect:\")\n",
    "print(f\"  Coefficient: {result['polite_diff_coef']:.3f}\")\n",
    "print(f\"  P-value: {result['polite_diff_pval']:.4f}\")\n",
    "print(f\"\\nModel Pseudo-R²: {result['pseudo_r2']:.3f}\")\n",
    "print(f\"N: {result['n_obs']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model summary\n",
    "print(result['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Sycophancy Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Win rate by sycophancy differential\n",
    "df_model['syco_diff_cat'] = pd.cut(\n",
    "    df_model['syco_diff'], \n",
    "    bins=[-4, -2, -1, 0, 1, 2, 4],\n",
    "    labels=['A << B', 'A < B', 'A ≈ B', 'A > B', 'A >> B', 'A >>> B']\n",
    ")\n",
    "\n",
    "win_by_diff = df_model.groupby('syco_diff_cat', observed=True).agg({\n",
    "    'a_wins': ['mean', 'count', 'std']\n",
    "}).droplevel(0, axis=1)\n",
    "win_by_diff.columns = ['win_rate', 'n', 'std']\n",
    "win_by_diff['se'] = np.sqrt(win_by_diff['win_rate'] * (1 - win_by_diff['win_rate']) / win_by_diff['n'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(win_by_diff))\n",
    "ax.bar(x, win_by_diff['win_rate'], yerr=1.96*win_by_diff['se'], capsize=5, color='steelblue')\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', label='Chance')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(win_by_diff.index, rotation=45, ha='right')\n",
    "ax.set_xlabel('Sycophancy Differential (A - B)')\n",
    "ax.set_ylabel('A Win Rate')\n",
    "ax.set_title('Win Rate by Sycophancy Differential')\n",
    "ax.legend()\n",
    "\n",
    "# Add sample sizes\n",
    "for i, (_, row) in enumerate(win_by_diff.iterrows()):\n",
    "    ax.annotate(f'n={int(row[\"n\"])}', (i, row['win_rate'] + 0.05), ha='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Heterogeneous Effects by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_syco.analysis.causal import run_heterogeneous_effects\n",
    "\n",
    "# Run separate regressions by topic\n",
    "het_effects = run_heterogeneous_effects(\n",
    "    df_model,\n",
    "    outcome_col='a_wins',\n",
    "    sycophancy_col='syco_diff',\n",
    "    moderator_col='topic',\n",
    "    control_cols=['polite_diff', 'length_diff'],\n",
    ")\n",
    "\n",
    "het_effects = het_effects.sort_values('sycophancy_coef', ascending=False)\n",
    "print(\"Sycophancy Effect by Topic:\")\n",
    "het_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize heterogeneous effects\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot coefficients with CIs\n",
    "y_pos = np.arange(len(het_effects))\n",
    "\n",
    "ax.barh(y_pos, het_effects['sycophancy_coef'], \n",
    "        xerr=[het_effects['sycophancy_coef'] - het_effects['sycophancy_ci_lower'],\n",
    "              het_effects['sycophancy_ci_upper'] - het_effects['sycophancy_coef']],\n",
    "        capsize=3, color='steelblue')\n",
    "\n",
    "ax.axvline(x=0, color='red', linestyle='--')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(het_effects['level'])\n",
    "ax.set_xlabel('Sycophancy Effect on Win Rate (log-odds)')\n",
    "ax.set_title('Heterogeneous Sycophancy Effects by Topic')\n",
    "\n",
    "# Add significance stars\n",
    "for i, row in enumerate(het_effects.itertuples()):\n",
    "    if row.sycophancy_pval < 0.01:\n",
    "        ax.annotate('**', (row.sycophancy_coef + 0.02, i), fontsize=12)\n",
    "    elif row.sycophancy_pval < 0.05:\n",
    "        ax.annotate('*', (row.sycophancy_coef + 0.02, i), fontsize=12)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Propensity Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_syco.analysis.causal import compute_propensity_scores, compute_ate\n",
    "\n",
    "# Define high sycophancy as treatment\n",
    "df_ps = df_model.copy()\n",
    "df_ps['high_syco_a'] = (df_ps['sycophancy_a'] >= 2).astype(int)\n",
    "\n",
    "# Compute propensity scores\n",
    "df_ps = compute_propensity_scores(\n",
    "    df_ps,\n",
    "    treatment_col='sycophancy_a',\n",
    "    covariate_cols=['topic', 'assistant_a_word_count', 'politeness_a'],\n",
    "    treatment_threshold=2,\n",
    ")\n",
    "\n",
    "# Propensity score distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "treated = df_ps[df_ps['high_sycophancy'] == 1]['propensity_score']\n",
    "control = df_ps[df_ps['high_sycophancy'] == 0]['propensity_score']\n",
    "\n",
    "ax.hist(treated, bins=30, alpha=0.5, label=f'High Sycophancy (n={len(treated)})', density=True)\n",
    "ax.hist(control, bins=30, alpha=0.5, label=f'Low Sycophancy (n={len(control)})', density=True)\n",
    "ax.set_xlabel('Propensity Score')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Propensity Score Distribution')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ATE with IPW\n",
    "ate_result = compute_ate(\n",
    "    df_ps,\n",
    "    treatment_col='high_sycophancy',\n",
    "    outcome_col='a_wins',\n",
    "    propensity_col='propensity_score',\n",
    ")\n",
    "\n",
    "print(\"AVERAGE TREATMENT EFFECT (IPW)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nEffect of high sycophancy (≥2) on win rate:\")\n",
    "print(f\"  ATE: {ate_result['ate']:.3f}\")\n",
    "print(f\"  95% CI: [{ate_result['ci_lower']:.3f}, {ate_result['ci_upper']:.3f}]\")\n",
    "print(f\"\\n  N treated: {ate_result['n_treated']:,}\")\n",
    "print(f\"  N control: {ate_result['n_control']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Robustness Check: Controlling for Model Fixed Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add model dummies (top 10 models only to avoid overfitting)\n",
    "top_models = df_model['model_a'].value_counts().head(10).index\n",
    "df_fe = df_model[df_model['model_a'].isin(top_models)].copy()\n",
    "\n",
    "# Prepare features with model dummies\n",
    "X = pd.get_dummies(df_fe[['syco_diff', 'polite_diff', 'length_diff', 'topic', 'model_a']], drop_first=True)\n",
    "X = sm.add_constant(X)\n",
    "y = df_fe['a_wins']\n",
    "\n",
    "# Fit\n",
    "model_fe = sm.Logit(y, X).fit(disp=0)\n",
    "\n",
    "print(\"MODEL WITH FIXED EFFECTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nSycophancy Differential:\")\n",
    "print(f\"  Coefficient: {model_fe.params['syco_diff']:.3f}\")\n",
    "print(f\"  P-value: {model_fe.pvalues['syco_diff']:.4f}\")\n",
    "print(f\"\\nPseudo-R²: {model_fe.prsquared:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary of Causal Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CAUSAL ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. SYCOPHANCY EFFECT ON WINNING:\")\n",
    "syco_or = result['syco_diff_or']\n",
    "print(f\"   - Each 1-point increase in sycophancy differential\")\n",
    "print(f\"     multiplies odds of winning by {syco_or:.2f}x\")\n",
    "print(f\"   - P-value: {result['syco_diff_pval']:.4f}\")\n",
    "\n",
    "print(\"\\n2. POLITENESS EFFECT (CONTROL):\")\n",
    "polite_or = np.exp(result['polite_diff_coef'])\n",
    "print(f\"   - Each 1-point increase in politeness differential\")\n",
    "print(f\"     multiplies odds of winning by {polite_or:.2f}x\")\n",
    "print(f\"   - P-value: {result['polite_diff_pval']:.4f}\")\n",
    "\n",
    "print(\"\\n3. HETEROGENEITY BY TOPIC:\")\n",
    "sig_topics = het_effects[het_effects['sycophancy_pval'] < 0.05]\n",
    "print(f\"   - Significant effects in {len(sig_topics)} of {len(het_effects)} topics\")\n",
    "if len(sig_topics) > 0:\n",
    "    strongest = sig_topics.iloc[0]\n",
    "    print(f\"   - Strongest effect: {strongest['level']} (β={strongest['sycophancy_coef']:.2f})\")\n",
    "\n",
    "print(\"\\n4. ROBUSTNESS:\")\n",
    "print(f\"   - Effect robust to model fixed effects: \" + \n",
    "      (\"Yes\" if model_fe.pvalues['syco_diff'] < 0.05 else \"No\"))\n",
    "print(f\"   - IPW ATE: {ate_result['ate']:.3f} [{ate_result['ci_lower']:.3f}, {ate_result['ci_upper']:.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Continue with `05_figures_for_paper.ipynb` for publication-ready figures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
